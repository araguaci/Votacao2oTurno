# An√°lise das elei√ß√µes para presidente do 2o turno

Datasets inclusos

Maiores informa√ß√µes na thread abaixo:

https://twitter.com/leonardodias/status/1592001220817870851

Caso queira rodar o notebook, pode rod√°-lo em sua m√°quina. Para isso basta instalar o Anaconda e rod√°-lo. 

https://www.anaconda.com

Tamb√©m √© poss√≠vel instalar usando pip. Veja o site oficial do Jupyter. Tanto faz rodar o Jupyter, mais leve, ou o JupyterLab, que tem mais extens√µes e m√≥dulos.

https://jupyter.org/

Caso queira rodar em cloud, recomendo o Google Colab, que √© bem simples, e permite que voc√™ armazene os datasets no Google Drive e acesse por l√°.

https://colab.research.google.com

Tamb√©m √© poss√≠vel criar um cluster EMR e usar o EMR Studio. Por√©m a cria√ß√£o de um cluster demanda tempo e tem custos mais altos. Mas √© poss√≠vel criar um para agregar ainda mais dados e aumentar o tamanho do dataset.

https://aws.amazon.com/pt/emr/features/studio/

Tamb√©m ser√° necess√°rio instalar o pyspark, seaborn, pandas e mais alguns outros. Dependendo do pacote que voc√™ instala, alguns j√° v√™m instalados. Mas geralmente pode ser necess√°rio instalar o pyspark. Voc√™ pode usar os comandos abaixo:

pip install pyspark seaborn pandas
conda install pyspark

No caso do conda, pode ser necess√°rio utilizar os pacots do conda_forge. Basta visitar a p√°gina desses projetos para verificar o comando utilizado.

Existem diversos servi√ßos de cloud para rodar notebooks al√©m do Google Colab e EMR Studio. Veja o artigo abaixo para mais op√ß√µes:

https://www.dataschool.io/cloud-services-for-jupyter-notebook/


## Subscribe

[@leonardodias](//twitter.com/leonardodias)

[Nov 14, 2022](https://twitter.com/leonardodias/status/1592001220817870851 "Read on X") ‚Ä¢ 24 tweets ‚Ä¢ 11 min read ‚Ä¢ [Read on X](https://twitter.com/leonardodias/status/1592001220817870851)

 

Gostam de dados, n√∫meros, manipula√ß√£o de dados e programa√ß√£o? Que tal uma thread educativa sobre o assunto usando os dados oficiais do sufr√°gio?  
  
Sigam o fio üßµüßµüßµ

Nessa thread vamos falar de:  
  
1) Engenharia de dados  
2) Enriquecimento de dados  
3) Qualidade de dados  
4) Ci√™ncia de dados  
5) An√°lise explorat√≥ria  
  
Tudo isso usando Spark SQL, Spark ML, Pandas, Seaborn e Python. Bora?

Primeiro os downloads: todos os datasets foram obtidos do portal [dadosabertos.tse.jus.br](http://dadosabertos.tse.jus.br). Basta buscar por 2002 e todos os datasets estar√£o l√°. Depois √© s√≥ descomprimir e utilizar √† vontade. Vamos l√°!

Usei um notebook Jupyter para a an√°lise. Primeiro importamos as bibliotecas. Voc√™ pode precisar instalar algumas delas. Sugiro conda ou pip. [![Image](https://pbs.twimg.com/media/Fhfl40bXkAciXm0.jpg)](https://pbs.twimg.com/media/Fhfl40bXkAciXm0.jpg)

Leitura dos datasets e cria√ß√£o dos dataframes: [![Image](https://pbs.twimg.com/media/FhfmAxtXgAEns_m.jpg)](https://pbs.twimg.com/media/FhfmAxtXgAEns_m.jpg)

Vamos examinar os schemas dos datasets. √â poss√≠vel ver alguns problemas, como campos data como string, por exemplo. [![Image](https://pbs.twimg.com/media/FhfmQJ6X0AYggJE.png)](https://pbs.twimg.com/media/FhfmQJ6X0AYggJE.png)[![Image](https://pbs.twimg.com/media/FhfmUZFWAAIgtzP.jpg)](https://pbs.twimg.com/media/FhfmUZFWAAIgtzP.jpg)[![Image](https://pbs.twimg.com/media/FhfmXd2XwAI3s_A.jpg)](https://pbs.twimg.com/media/FhfmXd2XwAI3s_A.jpg)

Na engenharia de dados nos preocupamos com qualidade dos dados, convers√£o de campos para timestamp e cria√ß√£o das chaves urna\_id e zona\_id que ser√£o utilizadas para fazer joins e tornar os dados verticalizados originais em horizontalizados para an√°lises diversas. [![Image](https://pbs.twimg.com/media/Fhfmlg7XwAYeGeW.png)](https://pbs.twimg.com/media/Fhfmlg7XwAYeGeW.png)[![Image](https://pbs.twimg.com/media/FhfmrWLWYAAwTiu.jpg)](https://pbs.twimg.com/media/FhfmrWLWYAAwTiu.jpg)[![Image](https://pbs.twimg.com/media/Fhfmwq7XwAY3IZk.jpg)](https://pbs.twimg.com/media/Fhfmwq7XwAY3IZk.jpg)[![Image](https://pbs.twimg.com/media/Fhfm172WQAEAK9M.jpg)](https://pbs.twimg.com/media/Fhfm172WQAEAK9M.jpg)

Para juntar todos os dataframes e agrup√°-los por urna\_id, foi necess√°rio um grande comando SQL cheio de fun√ß√µes matem√°ticas. Com isso criamos diversos campos √∫teis para a an√°lise de dados. [![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfnKL2XEAIUnGz.jpg)

Com o objetivo de juntar o m√°ximo de dados poss√≠veis, resolvi juntar tamb√©m o dataset de mes√°rios. A informa√ß√£o mais relevante que encontrei √© se eram volunt√°rios ou n√£o e o total de mes√°rios de cada zona. O n√∫mero √© por zona, n√£o por se√ß√£o. Da√≠ a necessidade do zona\_id. [![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfnfF_X0AIn_VQ.jpg)[![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfnlaVXoAEM7r0.jpg)

Com isso criamos o dataframe vm, que agora cont√©m dados de 3 datasets diferentes. [![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfnuuDWYAAVVBq.jpg)[![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfnzO5WYAEWb9U.jpg)

Como h√° muitas vari√°veis e √© dif√≠cil para um ser humano ficar analisando vari√°vel por vari√°vel, resolvi fazer uma an√°lise usando machine learning. Escolhi uma t√©cnica de machine learning n√£o supervisionado de agrupamento (clustering). Usei k=4 ap√≥s testar com outros n√∫meros. [![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfoWF_X0AAf7JI.png)[![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfobmhWIAAiaXT.jpg)

Para tentar entender como o algoritmo dividiu os dados, fiz algumas an√°lises com pivot usando o m√©todo crosstab no dataframe predictions. D√° para ver algumas coisas interessantes sobre como os dados ficaram separados. [![Image](/images/1px.png)](https://pbs.twimg.com/media/Fhfou6AWYAEVgSL.jpg)[![Image](/images/1px.png)](https://pbs.twimg.com/media/Fhfo-voXkAMaUxg.jpg)[![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfpEGqXEAIR-Ur.jpg)

Fizemos ent√£o a an√°lise gr√°fica. Aquele mesmo gr√°fico de bolinhas. Cada bolinha √© uma se√ß√£o. Os eixos s√£o os mesmos. S√≥ que agora estamos filtrando cada cluster descoberto pelo algoritmo de intelig√™ncia artificial utilizado. [![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfpRnJX0AAPVpQ.png)

Como ficou o cluster 0, o mais intrigante por ter mais variabilidade. Vejam os gr√°ficos.  
  
Nos eixos superior temos a concentra√ß√£o de frequ√™ncia na barra, E acima e ao lado direito, temos a distribui√ß√£o de frequ√™ncia de cada um dos itens coloridos pelo gr√°fico. [![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfpiFuXEAIHVrg.png)[![Image](/images/1px.png)](https://pbs.twimg.com/media/Fhfpt5tXgAEvHNe.png)[![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfpwYXXgAAlsCD.png)[![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfpzcFXgAMLdEw.png)

√öltimo gr√°fico do cluster 0: [![Image](/images/1px.png)](https://pbs.twimg.com/media/Fhfp7o1XgAEzwfS.png)

Como ficou o cluster 1. Muito interessante o car√°ter bimodal da frequ√™ncia das urnas que n√£o s√£o 2020, que foram todas agrupadas nesse grupo 1. [![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfqDvGWAAAW-u0.png)[![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfqHFaWIAAvpPz.png)[![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfqPMqWAAAfKfD.png)

Grupos 2 e 3 Vejam como ficou. Grupo 2, primeiros 2 gr√°ficos, grupo 3, 2 √∫ltimos. [![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfqWxKXwAEcDes.png)[![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfqZunX0AESvjs.png)[![Image](/images/1px.png)](https://pbs.twimg.com/media/Fhfqd9MXEAEusqk.png)[![Image](/images/1px.png)](https://pbs.twimg.com/media/Fhfqkk_X0AAgnlj.png)

Por √∫ltimo, fiz algumas an√°lises por algumas vari√°veis considerando a diferen√ßa entre eles. Vejam que interessante: [![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfqvwkXkAIpEka.jpg)[![Image](/images/1px.png)](https://pbs.twimg.com/media/Fhfq2zlWYAEgznz.jpg)[![Image](/images/1px.png)](https://pbs.twimg.com/media/Fhfq8LlWIAc-OL8.jpg)[![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfrBd2XkAEUvVm.jpg)

Continuando: [![Image](/images/1px.png)](https://pbs.twimg.com/media/FhfrGNDXwAEF2QJ.jpg)

Outra an√°lise que fiz foi procurar zonas onde havia mais de um tipo de urna. Encontrei algumas para verificar se h√° mesmo diferen√ßas entre essas se√ß√µes e se √© significativa.  
  
Escolhi a cidade de Registro, em SP, por ter v√°rios modelos de urna numa mesma zona. [![Image](/images/1px.png)](https://pbs.twimg.com/media/Fhfrq1TXkAEmkHJ.jpg)

O resultado √© que h√° mesmo diferen√ßa de resultados entre as se√ß√µes com determinados modelos. Mesmo sendo de uma mesma zona de uma mesma cidade. No entanto h√° diferen√ßas entre o n√∫mero de se√ß√µes com cada modelo. V√°rias coisas podem explicar, mas √© curioso de qualquer maneira. [![Image](/images/1px.png)](https://pbs.twimg.com/media/Fhfr-81XkAAmXcD.png)

H√° muitas possibilidades de analisar esses dados e tamb√©m de agregar mais dados, como geolocaliza√ß√£o, dados de clima e outros fatores interessantes.  
  
Que outros dados voc√™ agregaria? E o que gostaria de saber desses dados? Essa thread agora vai ser complementada por voc√™!

Espero, com essa thread educativa, inspirar muitos de voc√™s a trabalharem com dados, n√∫meros, estat√≠sticas, matem√°tica, big data, machine learning, ci√™ncia e engenharia de dados.  
  
Vamos? Obrigado por ler at√© aqui e espero que tenha gostado!

Link para o reposit√≥rio no GitHub:  
  
[github.com/leonardodiasda‚Ä¶](https://github.com/leonardodiasdatascientist/Votacao2oTurno)

[![](https://opengraph.githubassets.com/b5fcff31b859cbb7a8bb525f3320a5762058778baa7de606158cb4c6d6139342/leonardodiasdatascientist/Votacao2oTurno)](https://github.com/leonardodiasdatascientist/Votacao2oTurno)

[**GitHub - leonardodiasdatascientist/Votacao2oTurno** Contribute to leonardodiasdatascientist/Votacao2oTurno development by creating an account on GitHub.](https://github.com/leonardodiasdatascientist/Votacao2oTurno) [https://github.com/leonardodiasdatascientist/Votacao2oTurno](https://github.com/leonardodiasdatascientist/Votacao2oTurno)

